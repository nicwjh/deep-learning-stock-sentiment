{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 02 – MLP with TF-IDF (Setup Instructions)\n","\n","To run this notebook successfully:\n","\n","1. Make sure you have run **`01_data_processing.ipynb`** first, so that it creates:\n","   - `data_clean/merged_dataset.parquet`\n","   - `data_clean/split_indices.npz`\n","   - `outputs/eval_utils.py`\n","\n","2. Confirm that the project folder **`HODL Final Project`** exists in **your** Google Drive at:\n","   `My Drive/HODL Final Project`\n","\n","   - If this folder was shared with you, go to **\"Shared with me\"** in Google Drive,  \n","     right-click **`HODL Final Project` → \"Add shortcut to Drive\" → My Drive**.\n","\n","3. If your folder is in a different location or has a different name,  \n","   **edit the `BASE_PATH` variable in the first code cell**.\n","\n","4. Then go to **Runtime → Run all** and authorize Drive access when prompted.\n"],"metadata":{"id":"FbQSi7WBU3DI"}},{"cell_type":"code","execution_count":9,"metadata":{"id":"KZ5ge7BygFER","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765321360990,"user_tz":300,"elapsed":7246,"user":{"displayName":"Nicholas Wong","userId":"02446144671990464721"}},"outputId":"2e0f3f9b-963a-4a06-f4c4-fb7d43703aec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Training Data Shape: (1909, 5000)\n","Val Data Shape:     (395, 5000)\n","Test Data Shape:     (391, 5000)\n"]}],"source":["# 1. Initializations\n","!pip install keras-tuner -q\n","from tensorflow.keras import layers\n","import tensorflow as tf\n","from google.colab import drive\n","import keras\n","import keras_tuner as kt\n","import sys\n","import os\n","import random\n","import pandas as pd\n","import numpy as np\n","\n","SEED = 42\n","\n","# Python / NumPy / TF random seeds\n","random.seed(SEED)\n","np.random.seed(SEED)\n","tf.random.set_seed(SEED)\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# CHANGE THIS IF YOUR FOLDER IS IN A DIFFERENT PLACE\n","BASE_PATH = '/content/drive/MyDrive/HODL Final Project'\n","\n","DATA_CLEAN = f'{BASE_PATH}/data_clean'\n","OUTPUTS   = f'{BASE_PATH}/outputs'\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","#2 Import the Parquet file\n","\n","df = pd.read_parquet(f'{DATA_CLEAN}/merged_dataset.parquet')\n","\n","#3 Import the splits\n","splits = np.load(f'{DATA_CLEAN}/split_indices.npz')\n","train_idx = splits['train_indices']\n","val_idx   = splits['val_indices']\n","test_idx  = splits['test_indices']\n","\n","df_train = df.iloc[train_idx]\n","df_val   = df.iloc[val_idx]\n","df_test  = df.iloc[test_idx]\n","\n","# 4. Prepare Data for MLP (Vectorization)\n","tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2), stop_words='english')\n","\n","# Fit only on TRAIN, then transform the others\n","X_train = tfidf.fit_transform(df_train['text']).toarray() # .toarray() converts sparse matrix for Keras\n","X_val   = tfidf.transform(df_val['text']).toarray()\n","X_test  = tfidf.transform(df_test['text']).toarray()\n","\n","y_train = df_train['label'].values\n","y_val   = df_val['label'].values\n","y_test  = df_test['label'].values\n","\n","print(f\"Training Data Shape: {X_train.shape}\")\n","print(f\"Val Data Shape:     {X_val.shape}\")\n","print(f\"Test Data Shape:     {X_test.shape}\")\n"]},{"cell_type":"code","source":["def build_model(hp):\n","    # hyperparameters\n","    num_layers = hp.Choice(\"num_layers\", [1, 2, 3])\n","    units      = hp.Choice(\"units\", [32, 64, 128])\n","\n","    # input\n","    inputs = keras.Input(shape=(5000,))\n","\n","    # stack num_layers hidden layers, each with 'units' neurons\n","    x = inputs\n","    for i in range(num_layers):\n","        x = keras.layers.Dense(units, activation=\"relu\", name=f\"Hidden{i+1}\")(x)\n","\n","    # output layer\n","    outputs = layers.Dense(1, activation=\"sigmoid\", name=\"Output\")(x)\n","\n","    model = keras.Model(inputs, outputs)\n","\n","    model.compile(\n","        optimizer=\"adam\",\n","        loss=\"binary_crossentropy\",\n","        metrics=[\"accuracy\"]\n","    )\n","    return model"],"metadata":{"id":"kE9NLdq3k70w","executionInfo":{"status":"ok","timestamp":1765321360998,"user_tz":300,"elapsed":2,"user":{"displayName":"Nicholas Wong","userId":"02446144671990464721"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Initialize the tuner\n","tuner = kt.GridSearch(\n","    hypermodel=build_model,\n","    objective=\"val_accuracy\",\n","    overwrite=True,\n","    directory=\"kt_dir\",\n","    project_name=\"stock_prediction_mlp\"\n",")\n","\n","\n","\n","\n","tuner.search(\n","    X_train, y_train,\n","    epochs=20,\n","    batch_size=32,\n","    verbose=1,\n","    validation_data=(X_val, y_val)\n",")\n","tuner.search_space_summary()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0v7jYm6Uvoyr","executionInfo":{"status":"ok","timestamp":1765321438683,"user_tz":300,"elapsed":77684,"user":{"displayName":"Nicholas Wong","userId":"02446144671990464721"}},"outputId":"1011eae4-33f3-4583-8731-70e68a99de61"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 9 Complete [00h 00m 09s]\n","val_accuracy: 0.6101265549659729\n","\n","Best val_accuracy So Far: 0.6227847933769226\n","Total elapsed time: 00h 01m 18s\n","Search space summary\n","Default search space size: 2\n","num_layers (Choice)\n","{'default': 1, 'conditions': [], 'values': [1, 2, 3], 'ordered': True}\n","units (Choice)\n","{'default': 32, 'conditions': [], 'values': [32, 64, 128], 'ordered': True}\n"]}]},{"cell_type":"code","source":["tuner.results_summary()"],"metadata":{"id":"LdzVS6W71m3c","executionInfo":{"status":"ok","timestamp":1765321438717,"user_tz":300,"elapsed":32,"user":{"displayName":"Nicholas Wong","userId":"02446144671990464721"}},"outputId":"c06f88ce-5790-4fae-a380-af81dd660638","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Results summary\n","Results in kt_dir/stock_prediction_mlp\n","Showing 10 best trials\n","Objective(name=\"val_accuracy\", direction=\"max\")\n","\n","Trial 0000 summary\n","Hyperparameters:\n","num_layers: 1\n","units: 32\n","Score: 0.6227847933769226\n","\n","Trial 0003 summary\n","Hyperparameters:\n","num_layers: 2\n","units: 32\n","Score: 0.6151898503303528\n","\n","Trial 0004 summary\n","Hyperparameters:\n","num_layers: 2\n","units: 64\n","Score: 0.6151898503303528\n","\n","Trial 0005 summary\n","Hyperparameters:\n","num_layers: 2\n","units: 128\n","Score: 0.6151898503303528\n","\n","Trial 0006 summary\n","Hyperparameters:\n","num_layers: 3\n","units: 32\n","Score: 0.6126582026481628\n","\n","Trial 0001 summary\n","Hyperparameters:\n","num_layers: 1\n","units: 64\n","Score: 0.6101265549659729\n","\n","Trial 0008 summary\n","Hyperparameters:\n","num_layers: 3\n","units: 128\n","Score: 0.6101265549659729\n","\n","Trial 0002 summary\n","Hyperparameters:\n","num_layers: 1\n","units: 128\n","Score: 0.607594907283783\n","\n","Trial 0007 summary\n","Hyperparameters:\n","num_layers: 3\n","units: 64\n","Score: 0.5898734331130981\n"]}]},{"cell_type":"code","source":["\n","# 1 Get the best model from the search\n","best_model = tuner.get_best_models(num_models=1)[0]\n","\n","print(\"\\nBest Model Hyperparameters:\")\n","best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n","print(f\"Layers: {best_hps.get('num_layers')}\")\n","print(f\"Units:  {best_hps.get('units')}\")\n","\n","# 2 Add the eval_utils path  to import the grading tool\n","import sys\n","sys.path.append(OUTPUTS)\n","from eval_utils import evaluate_model, print_results\n","\n","# 3 Predict on the Test Set\n","y_prob = best_model.predict(X_test).flatten()\n","y_pred = (y_prob > 0.5).astype(int)\n","\n","# 4. Score it\n","results = evaluate_model(y_test, y_pred, y_prob)\n","\n","print(\"\\n\" + \"=\"*30)\n","print(\"FINAL MLP RESULTS\")\n","print(\"=\"*30)\n","print_results(results, \"tuned MLP\")"],"metadata":{"id":"sTMOvn71yxRT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765321439722,"user_tz":300,"elapsed":784,"user":{"displayName":"Nicholas Wong","userId":"02446144671990464721"}},"outputId":"11709728-8890-41ec-e67b-980a70bc97e0"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n","  saveable.load_own_variables(weights_store.get(inner_path))\n"]},{"output_type":"stream","name":"stdout","text":["\n","Best Model Hyperparameters:\n","Layers: 1\n","Units:  32\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n","\n","==============================\n","FINAL MLP RESULTS\n","==============================\n","tuned MLP: 52.17% acc, 0.534 F1, 0.538 AUC\n"]}]}]}